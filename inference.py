# -*- coding: utf-8 -*-
"""inference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13FXXxCybRo5jrOFdUKEZKwzVT-gKMuQv
"""

# inference_api.py - EXACT AS YOUR CODE

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
import shutil
import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from Bio import SeqIO
from torch_geometric.data import Data
from torch_geometric.nn import GATConv, global_mean_pool
from torch_geometric.loader import DataLoader
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import networkx as nx
from pathlib import Path

Path("uploads").mkdir(exist_ok=True)
Path("results").mkdir(exist_ok=True)

# EXACT MODEL CLASS FROM YOUR CODE
class GAT_Light(nn.Module):
    def __init__(self, num_abs):
        super().__init__()
        self.gat1 = GATConv(1, 16, heads=4, dropout=0.5)
        self.gat2 = GATConv(16*4, 8, heads=2, dropout=0.5)
        self.fc1 = nn.Linear(8*2, 32)
        self.fc2 = nn.Linear(32, num_abs)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)
        self.sigmoid = nn.Sigmoid()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = self.gat1(x, edge_index)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.gat2(x, edge_index)
        x = self.relu(x)
        x = global_mean_pool(x, batch)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.sigmoid(self.fc2(x))
        return x

app = FastAPI(title="AMR Prediction API", version="1.0.0")

model = None
scaler = None
device = None
num_labels = None

@app.on_event("startup")
async def startup_event():
    global model, scaler, device, num_labels

    print("[INIT] Loading model...")
    device = torch.device('cpu')

    # Check files exist
    if not os.path.exists('best_gat_realistic.pth'):
        print("❌ Model not found!")
        return

    if not os.path.exists('ncbi_features.csv'):
        print("❌ Scaler data not found!")
        return

    if not os.path.exists('amr_labels_realistic_distribution.csv'):
        print("❌ Labels file not found!")
        return

    # Load model
    labels_df_temp = pd.read_csv('amr_labels_realistic_distribution.csv')
    num_labels = labels_df_temp.shape[1] - 1

    model = GAT_Light(num_labels).to(device)
    model.load_state_dict(torch.load('best_gat_realistic.pth', map_location=device))
    model.eval()

    # Load scaler
    scaler_data = pd.read_csv('ncbi_features.csv').drop('genome_id', axis=1).values.astype(np.float32)
    scaler = StandardScaler()
    scaler.fit(scaler_data)

    print("✓ Model ready!")

@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    """Upload FASTA file and get AMR predictions"""

    try:
        if model is None:
            raise HTTPException(status_code=500, detail="Model not loaded")

        # Save uploaded file
        file_path = f"uploads/{file.filename}"
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)

        # Read FASTA
        sequences = []
        for record in SeqIO.parse(file_path, 'fasta'):
            seq = str(record.seq).upper()
            sequences.append(seq)

        if not sequences:
            raise HTTPException(status_code=400, detail="No valid sequences")

        full_sequence = ''.join(sequences)

        # EXACT KMER EXTRACTION FROM YOUR CODE
        bases = ['A', 'T', 'G', 'C']

        def generate_kmers(k=6):
            kmers = []
            def backtrack(current):
                if len(current) == k:
                    kmers.append(current)
                    return
                for base in bases:
                    backtrack(current + base)
            backtrack('')
            return kmers

        all_kmers = generate_kmers(k=6)
        kmer_counts = {kmer: 0 for kmer in all_kmers}

        k = 6
        for i in range(len(full_sequence) - k + 1):
            kmer = full_sequence[i:i+k]
            if kmer in kmer_counts:
                kmer_counts[kmer] += 1

        feature_vector = np.array([kmer_counts.get(kmer, 0) for kmer in all_kmers], dtype=np.float32).reshape(1, -1)
        feature_vector = scaler.transform(feature_vector)

        # CREATE GRAPH - EXACT FROM YOUR CODE
        x = torch.tensor(feature_vector.reshape(-1, 1), dtype=torch.float32)
        edges = []
        for i in range(len(feature_vector[0]) - 1):
            edges.append([i, i+1])
            edges.append([i+1, i])
        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous() if edges else torch.empty((2, 0), dtype=torch.long)
        graph = Data(x=x, edge_index=edge_index)

        # PREDICT
        with torch.no_grad():
            loader = DataLoader([graph], batch_size=1)
            for batch in loader:
                batch = batch.to(device)
                pred = model(batch)

        pred = pred.cpu().numpy()[0]

        # ANTIBIOTIC NAMES
        labels_df = pd.read_csv('amr_labels_realistic_distribution.csv')
        antibiotics = labels_df.columns[1:].tolist()

        resistant_count = sum(1 for p in pred if p > 0.5)
        susceptible_count = len(antibiotics) - resistant_count

        # SAVE RESULTS CSV
        results_df = pd.DataFrame({
            'antibiotic': antibiotics,
            'confidence_%': np.round(pred * 100, 1),
            'prediction': ['RESISTANT' if p > 0.5 else 'SUSCEPTIBLE' for p in pred]
        })

        csv_path = f"results/{file.filename.split('.')[0]}_results.csv"
        results_df.to_csv(csv_path, index=False)

        # GENERATE GRAPH - EXACT FROM YOUR CODE
        G = nx.Graph()

        for i in range(len(antibiotics)):
            conf = pred[i]
            ab = antibiotics[i]
            label = "R" if conf > 0.5 else "S"
            color = '#FF3333' if conf > 0.5 else '#33DD33'
            G.add_node(i, label=label, antibiotic=ab, confidence=conf, color=color)

        antibiotic_classes = {
            'aminoglycosides': [0, 1, 2, 3, 4],
            'penicillins': [5, 6, 7],
            'cephalosporins': [8, 9, 10, 11, 12, 13],
            'carbapenems': [14, 15, 16, 17, 18],
            'fluoroquinolones': [19, 20, 21],
            'macrolides': [22, 23],
            'tetracyclines': [24, 25],
            'others': [26, 27, 28, 29] if len(antibiotics) >= 30 else []
        }

        for class_name, indices in antibiotic_classes.items():
            for i in range(len(indices)):
                for j in range(i+1, len(indices)):
                    G.add_edge(indices[i], indices[j])

        fig, ax = plt.subplots(figsize=(18, 14))
        pos = nx.spring_layout(G, k=1.5, iterations=150, seed=42)

        node_colors = [G.nodes[node]['color'] for node in G.nodes()]

        nx.draw_networkx_nodes(G, pos, node_size=1200, node_color=node_colors,
                              alpha=0.95, edgecolors='black', linewidths=2.5, ax=ax)
        nx.draw_networkx_edges(G, pos, alpha=0.25, width=1.5, ax=ax)

        labels = {}
        for node in G.nodes():
            ab_short = G.nodes[node]['antibiotic'][:12]
            label = G.nodes[node]['label']
            conf = G.nodes[node]['confidence'] * 100
            labels[node] = f"{ab_short}\n{label} {conf:.0f}%"

        nx.draw_networkx_labels(G, pos, labels, font_size=9, font_weight='bold',
                               font_color='white', ax=ax)

        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='#FF3333', edgecolor='black', linewidth=2,
                  label=f'Resistant - {resistant_count}'),
            Patch(facecolor='#33DD33', edgecolor='black', linewidth=2,
                  label=f'Susceptible - {susceptible_count}')
        ]

        ax.legend(handles=legend_elements, loc='upper left', fontsize=14, framealpha=0.98)
        ax.set_title('AMR Prediction Network', fontsize=16, weight='bold', pad=25)
        ax.axis('off')

        plt.tight_layout()
        graph_path = f"results/{file.filename.split('.')[0]}_graph.png"
        plt.savefig(graph_path, dpi=200, bbox_inches='tight', facecolor='white')
        plt.close()

        return {
            "status": "success",
            "resistant": resistant_count,
            "susceptible": susceptible_count,
            "predictions": [
                {"antibiotic": ab, "confidence": float(conf), "prediction": "RESISTANT" if conf > 0.5 else "SUSCEPTIBLE"}
                for ab, conf in zip(antibiotics, pred)
            ],
            "csv_file": csv_path,
            "graph_file": graph_path
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)